---
title: "DMI Hands-On 3"
author: "Ariana Murillo Hernandez and Xareni Reyes Soto"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"      
output:
  html_document:
    toc: true
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Exercise 1

[Stamey et al. 1989](https://www.auajournals.org/doi/10.1016/S0022-5347%2817%2941175-X) examined the correlation between the level of prostate-specific antigen (PSA) and a number of clinical measures in men who were about to receive a radical prostatectomy. PSA is a protein that is produced by the prostate gland. The higher a manâ€™s PSA level, the more likely it is that he has prostate cancer.  
Use the [prostate cancer dataset](data/prostate_data.txt), described [here](data/prostate_description.txt),  to train a model that predicts log of prostate-specific antigen. 
The variables are    

- log cancer volume (lcavol)  
- log prostate weight (lweight)  
- age  
- log of the amount of benign prostatic hyperplasia (lbph)   
- seminal vesicle invasion (svi)  
- log of capsular penetration (lcp)  
- Gleason score (gleason)    
- percent of Gleason scores 4 or 5 (pgg45)  

You can ignore column named "train" and do your own data splitting.  
Do not forget to perform feature selection!   
You can use as examples the [Linear Regression Lab](https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch3-linreg-lab.html) and the section related to feature selection from  [Lab: Linear Models and Regularization Methods
](https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch6-varselect-lab.html) from the book [An Introduction to Statistical Learning](https://www.statlearning.com/).


```{r}
library(dplyr)
library(leaps)
library(caret)

# In this exercise, we need to do linear regression. We have multiple independent variables and one dependent variable, so we will perform Multiple Linear Regression
data_prostate <- read.table("data/prostate_data.txt", sep= "\t", header=TRUE)
# Then delete the first column, so that it is not repeated
data_prostate <- data_prostate[, -1]

# EDA
# 1. Check the data types
# 2. Check for missing values
# 3. Check for duplicate rows
# 4. Statistics summary

# 1. Check the data types
str(data_prostate)

# 2. We check for missing values
missing_counts <- colSums(is.na(data_prostate))
print(missing_counts)

# 3. Check if there are any duplicate rows in the table
any(duplicated(data_prostate))     # returns FALSE

# 4. Statistics summary
summary(data_prostate)

# Ignore the column 'train' as suggested by the exercise
data_prostate <- data_prostate %>% dplyr::select(-train)

# Split the data intro training and testing sets
set.seed(100)
train_index <- createDataPartition(data_prostate$lpsa, p = 0.8, list = FALSE)
train_data <- data_prostate[train_index, ]
test_data <- data_prostate[-train_index, ]

# Perform Feature Selection to determine which subset of predictors we should include,
# use Subset Selection
complete_model <- lm(lpsa ~ ., data = train_data)
step_model <- step(complete_model, direction = "both", trace = FALSE) # This is Stepwise Selection

# Info about selected model
summary(step_model) # Stepwise selection kept the most statistically significant predictors, which are: lcavol, lweight, age, lbph and svi. However, according to the p-values, lbph is not statistically significant so we may exclude it 
# TODO: evaluate removing lbph

# Refit using the predictors selected in previous step, without lbph
final_model <- lm(lpsa ~ lcavol + lweight + age + lbph + svi, data = train_data)

# Evaluation of the model
predictions <- predict(final_model, test_data)
mse <- mean((predictions - test_data$lpsa)^2) # Mean squared error
rmse <- sqrt(mse) # Root mean squared error
r_squared <- cor(predictions, test_data$lpsa)^2 # TODO: what is this???

# Evaluation metrics
cat("RMSE:", rmse, "\n")
cat("R-squared:", r_squared, "\n")

# Plot the residuals to check the model assumptions
plot(final_model$fitted.values, residuals(final_model), 
     main = "Residual plot",
     xlab = "Fitted values", 
     ylab = "Residuals", 
     pch = 20, col = "darkblue")
abline(h = 0, col = "darkorange")

# TODO: Explain why the residuals look good

# TODO: Next steps: check for multicollinearity (why is this agood idea?)and k-cross fold validation

# Perform cross-validation to check the stability of the model


```

```{r}


```



# Exercise 2

Use the [breast cancer dataset](data/breat_cancer_data.csv) to train a model that predicts whether a future tumor image (with unknown diagnosis) is a benign or malignant tumor. Try different machine learning algorithms such as:   
- KNNs  
- Decision trees  
- Random forest  
- Logistic Regression  

The breast cancer dataset contains digitized breast cancer image features, and was created by [Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). Each row in the data set represents an image of a tumor sample, including the diagnosis (benign or malignant) and several other measurements (nucleus texture, perimeter, area, and more). Diagnosis for each image was conducted by physicians.

Do not forget to perform hyperparameter tuning!   
Which of all models performs better for this data? Discuss.  

Generate a ROC curve for all the models. 

You can use as a guide the analysis of this dataset included in the [chapter 5](https://datasciencebook.ca/classification1.html) of the Data Science, A First Introduction Book.
Additionally, for further information and ideas, you can check [this post](https://www.rebeccabarter.com/blog/2020-03-25_machine_learning/)

```{r}
# TODO: do not forget hyperparameter tuning
# TODO: the teacher suggested logistic regression, random forest, decision tree for this exercise
# TOOD: Answer which model performs best
library(ggplot2)
library(dplyr)
library(caret)
library(class)
library(pROC)

data_breast_cancer <- read.csv("data/breat_cancer_data.csv", sep= ",", header=TRUE)
#data1 <- read.csv("/home/xrs/Downloads/breast+cancer+wisconsin+diagnostic/wdbc.data", sep= ",", header=TRUE)

## Exploratory Data Analysis
# 1. Check the data types
str(data_breast_cancer)  # The data types look correct: id has type integer, diagnosis has type char and all the rest have type num 

# 2. Check if there are missing values
missing_counts <- colSums(is.na(data_breast_cancer))
print(missing_counts)    # Only column "X" has 569 NA's, no missing values in the other columns

# 3. Check unique values
unique(data_breast_cancer$diagnosis) # There are only two values: "M" (malign) and "B" (benign)

# 4. Check if there are any duplicate rows in the table
any(duplicated(data_breast_cancer))     # returns FALSE

# 5. Statistics summary
summary(data_breast_cancer)

# 6. Look at the distribution of the target variable: diagnosis
num_counts <- as.data.frame(table(data_breast_cancer$diagnosis)) # There are 357 benign samples and 212 malign samples

## Data pre-processing
# Drop unnecessary columns (the last one)
data_breast_cancer <- data_breast_cancer %>% select(-id, -X)

# Select only the diagnosis column and the next 10 columns (containing "..._mean")
selected_columns <- c("diagnosis", "radius_mean", "texture_mean","perimeter_mean", "area_mean", "smoothness_mean","compactness_mean", "concavity_mean","concave.points_mean", "symmetry_mean", "fractal_dimension_mean")
data_selected <- data_breast_cancer[selected_columns]

# Convert the categorical variable "diagnosis" to the factor data type for more efficiency in memory use and better performance in ML classification models
data_selected$diagnosis <- factor(data_selected$diagnosis)
# Verify the conversion to factor is done correctly
str(data_selected) # The column "diagnosis" appears now as Factor

# Normalize the data: this step is crucial for the KNN algorithm
preProcessValues <- preProcess(data_selected[-1], method = c("center","scale"))
data_normalized<- predict(preProcessValues, data_selected[-1])

data_final <- cbind(diagnosis = data_selected$diagnosis, data_normalized)

# Split the data into training and testing sets
set.seed(100)
trainIndex <- createDataPartition(data_final$diagnosis, p = 0.8, list = FALSE)
train_data <- data_final[trainIndex, ]
test_data <- data_final[-trainIndex, ]

```
Now that we have explored and pre-processed the data, we proceed with the KNN algorithm.
```{r}
## KNN algorithm
# The key hyperparameter for this model is K, the number of neighbors to consider.
# Choose the best value of K (i.e. tune the hyperparameter K) by trying different values and selecting the one that gives the highest accuracy
k_values<- seq(1, 20, by = 2)
# Calculate accuracy
accuracy <- sapply(k_values, function(k) {
  knn_model <- knn(train = train_data[-1], test = test_data[-1],
                   cl = train_data$diagnosis, k = k)
  mean(knn_model == test_data$diagnosis)
})

best_k <- k_values[which.max(accuracy)] # The best value for K is 9

# Train final KNN model with the best K
knn_pred <- knn(train = train_data[-1], test = test_data[-1],
                cl = train_data$diagnosis, k = best_k)

# Evaluate the model
confusion_matrix <- confusionMatrix(knn_pred, test_data$diagnosis)
print(confusion_matrix)

# Generate ROC curve for KNN
roc_curve_knn <- roc(as.numeric(test_data$diagnosis)-1, as.numeric(knn_pred)-1)
plot(roc_curve_knn, col = "#ca3517", main = "ROC Curve for the KNN model") # The "curve" looks like this because our model outputs discrete labels ("M" or"B") instead of continuous values
auc(roc_curve_knn) # The area under the ROC curve is 0.941

# TODO: The column "diagnosis" has already the correct classification
# TODO: Should I delete column "diagnosis" and "X"? Why is "X" added?

# For the K-nearest neighbor algorithm, we need to first standardize the data
```
We will next use a decision tree as model.
```{r}
# We have already have done an important part of the work, since we have explored, cleaned, normalized and split the data
library(rpart)
library(rpart.plot)

## Decision tree
# Train Decision Tree model using rpart
decision_tree_model <- rpart(diagnosis ~ ., data = train_data, method = "class")

# Visualize the Decision Tree
rpart.plot(decision_tree_model, main = "Decision Tree for the Diagnosis of Breast Cancer")

# Make predictions
predictions_dtree <- predict(decision_tree_model, test_data[-1], type = "prob")

# Convert probabilities into diagnosis labels
predicted_classes_dtree <-ifelse(predictions_dtree[,2] > 0.5, "M", "B")
predicted_classes_dtree <-factor(predicted_classes_dtree, levels = levels(test_data$diagnosis))

# Evaluate the model
confusion_matrix_dtree <- confusionMatrix(predicted_classes_dtree, test_data$diagnosis)
print(confusion_matrix_dtree)

# Generate ROC Curve for Decision Tree
roc_curve_dt <- roc(as.numeric(test_data$diagnosis)-1, as.numeric(predicted_classes_dtree)-1)
plot(roc_curve_dt, col = "#063970", main = "ROC Curve for the Decision Tree model")
auc(roc_curve_dt) # The area under the ROC curve is 0.9199


```

# Exercise 3  

Use [The Cancer Genome Atlas (TCGA)](https://www.genome.gov/Funded-Programs-Projects/Cancer-Genome-Atlas) gene expression data of two different cancer types to build a machine learning model that identifies whether a given sample (gene counts) belongs to one or the other. The TCGA is a comprehensive and coordinated effort to accelerate our understanding of the molecular basis of cancer through the application of genome analysis technologies, including large-scale genome sequencing. The program has generated, analyzed, and made available genomic sequence, expression, methylation, and copy number variation data on over 11,000 individuals who represent over 30 different types of cancer. 
After building your model, you should predict the cancer types for [10 unkwnon samples](data/unknwown_samples.tsv).  

For this task, you should retrieve the TCGA data from the [Genomic Data Commons Data Portal](https://portal.gdc.cancer.gov/). If necessary you can watch [the video uploaded in the Campus Global](https://aulaglobal.upf.edu/mod/resource/view.php?id=1483539). The video assumes that you have previously installed the [GDC data transfer tool](https://gdc.cancer.gov/access-data/gdc-data-transfer-tool). 

Each team will work with two specific cancer types, that will be assigned in class.

Important notice: if you do not have a lot of hard drive space in your laptop, you can modify the manifest file to download only 50 samples per cancer types. 


```{r}

```



# session info {.unnumbered}

```{r, results='asis',  echo=FALSE, message=FALSE }
sessionInfo()
```
